{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逆向最大匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMM(object):\n",
    "    def __init__(self,dic_path):\n",
    "        self.dictionary=set()\n",
    "        self.maximum=0\n",
    "        #读取词典\n",
    "        with open(dic_path,'r',encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line=line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                self.dictionary.add(line)\n",
    "                self.maximum=max(self.maximum,len(line))\n",
    "                \n",
    "    def cut(self,text):\n",
    "        result=[]\n",
    "        index=len(text)\n",
    "        while index>0:\n",
    "            word=None\n",
    "            for size in range(self.maximum,0,-1):\n",
    "                if index-size<0:\n",
    "                    continue\n",
    "                piece=text[(index-size):index]\n",
    "                if piece in self.dictionary:\n",
    "                    word=piece\n",
    "                    result.append(word)\n",
    "                    index-=size\n",
    "                    print(word)\n",
    "                    break\n",
    "                if word is None:\n",
    "                    index-=1\n",
    "        return result[::-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    text='南京市长江大桥'\n",
    "    tokenizer=IMM('../../Data/learning-nlp-master/chapter-3/data/imm_dic.utf8')\n",
    "    print(tokenizer.cut(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "长江大桥\n",
      "南京市\n",
      "['南京市', '长江大桥']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正向最大匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MM(object):\n",
    "    def __init__(self,dic_path):\n",
    "        self.dictionary=set()\n",
    "        self.maximum=0\n",
    "        #读取词典\n",
    "        with open(dic_path,'r',encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                line=line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                self.dictionary.add(line)\n",
    "                self.maximum=max(self.maximum,len(line))\n",
    "    def cut(self,text):\n",
    "        result=[]\n",
    "        index=0\n",
    "        l=len(text)\n",
    "        while index<l:\n",
    "            word=None\n",
    "            for size in range(self.maximum,0,-1):\n",
    "                if l-index-size<0:\n",
    "                    continue\n",
    "                piece=text[index:index+size]\n",
    "                if piece in self.dictionary:\n",
    "                    word=piece\n",
    "                    result.append(word)\n",
    "                    index+=size\n",
    "                    break\n",
    "                if word is None:\n",
    "                    result.append(text[index:index+1])\n",
    "                    index+=1\n",
    "        return result[:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    text='南京市长江大桥'\n",
    "    tokenizer=MM('../../Data/learning-nlp-master/chapter-3/data/imm_dic.utf8')\n",
    "    print(tokenizer.cut(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['南京市长', '江', '大桥']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全模式: 中文/分词/是/文本/文本处理/本处/处理/不可/不可或缺/或缺/的/一步/！\n",
      "精确模式 中文/分词/是/文本处理/不可或缺/的/一步/！\n",
      "搜索引擎模式 中文/分词/是/文本/本处/处理/文本处理/不可/或缺/不可或缺/的/一步/！\n"
     ]
    }
   ],
   "source": [
    "sent='中文分词是文本处理不可或缺的一步！'\n",
    "seg_list=jieba.cut(sent,cut_all=True)\n",
    "print('全模式:','/'.join(seg_list))\n",
    "seg_list=jieba.cut(sent,cut_all=False)\n",
    "print('精确模式','/'.join(seg_list))\n",
    "seg_list=jieba.cut_for_search(sent)\n",
    "print('搜索引擎模式','/'.join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实战之高频词提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(path):\n",
    "    with open(path,'r',encoding='gbk',errors='ignore') as f:\n",
    "        content=''\n",
    "        for l in f:\n",
    "            l=l.strip()\n",
    "            content+=l\n",
    "        return content\n",
    "def get_TF(words,topK=10):\n",
    "    tf_dic={}\n",
    "    for w in words:\n",
    "        tf_dic[w]=tf_dic.get(w,0)+1\n",
    "    return sorted(tf_dic.items(),key=lambda x:x[1],reverse=True)[:topK]\n",
    "def stop_words(path):\n",
    "    with open(path,'r',encoding='utf8') as f:\n",
    "        return [l.strip() for l in f]\n",
    "    \n",
    "def main():\n",
    "    import glob\n",
    "    import random\n",
    "    import jieba\n",
    "    stopWords=stop_words('../../Data/learning-nlp-master/chapter-3/data/stop_words.utf8')\n",
    "    files=glob.glob('../../Data/learning-nlp-master/chapter-3/data/news/C000013/*.txt')\n",
    "    corpus=[get_content(x) for x in files]\n",
    "    sample_inx=random.randint(0,len(corpus))\n",
    "    split_words=[x for x in jieba.cut(corpus[sample_inx]) if x not in stopWords]\n",
    "#     print(sample_inx)\n",
    "#     print(files[sample_inx])\n",
    "    print('样本之一:'+corpus[sample_inx])\n",
    "    print('样本分词效果:'+'/'.join(split_words))\n",
    "    print('topK10:'+str(get_TF(split_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本之一:&nbsp;很多女性对乳腺增生特别紧张，担心这是乳腺癌的前兆。其实，乳腺增生仅仅是由于女性内分泌失调——也就是雌激素增高、孕激素降低所造成的乳腺结构紊乱，别担心它一定会转变成乳腺癌。乳腺增生容易转癌吗?什么是乳腺增生症很多女性乳腺增生症主要表现为周期性乳房疼痛，乳腺腺体增厚或出现团块，并有压痛。同时还会有情绪改变，如生气、紧张、发怒、焦虑、抑郁等，工作、生活规律改变、劳累，甚至天气变化等都会使疼痛加重。有些妇女平时并不感到乳房疼痛，但健康检查时医生告诉她患有乳腺增生症后，她便经常感到乳房疼痛。而患者心情舒畅时，乳房疼痛的症状又会减轻。乳腺增生会很容易的转成乳腺癌吗？绝大多数乳腺增生症患者在其绝经后就会不治而愈，而不是得了乳腺增生就一定会转变成乳腺癌。只有极少数中度、重度不典型乳腺增生可能会转变为乳腺癌。［提示］乳房上长有肿块，无疼痛，或者仅仅有些刺痛或钝痛；非哺乳期的妇女，忽然出现乳头流水，要考虑可能是乳腺癌，应提早去医院检查。精神作用非常大精神过度紧张会使乳腺增生症加重，乳房疼痛更明显。当女性总是处于怒、愁、忧、虑等不良情绪状态，就会抑制卵巢的排卵功能，出现孕酮减少，使雌激素相对增高，导致乳腺增生。下一页：乳腺增生预防是关键如何预防乳腺增生？1.保持心情的舒畅、情绪的乐观是乳腺增生的最好防御武器。2.年龄在16-50岁的女性，都应定期进行乳腺普查，月经后第3-7天为最佳检查时机，可通过自查、触诊、钼钯等方式检查。35岁以上的女性应该1-2年做一次；50岁以上的女性应一年一次；高危人群(乳腺病家族史、卵巢癌、腺体癌)，有重度增生的女性应半年检查一次，进行动态观察。20-35岁的女性应3年进行一次红外线或乳腺外科检查。3.减少人工流产次数，以减少乳腺增生的概率。4.生活规律、适当运动。平时应劳逸结合，睡眠充足，少熬夜；适当进行跑步、扩胸等可以增强胸部健美的运动。5.哺乳时间要充分。女性产后不哺乳或哺乳不足8个月，会造成乳汁淤积，引发乳腺疾病的概率升高。6.避免激素药物和美容产品的使用。7.最好不要佩戴过紧或是有挤压隆胸效果的胸罩，这影响乳房的新陈代谢和淋巴回流，导致乳腺增生。8.减少高能量的补品及食品。饮食以清淡为主，多吃绿叶蔬菜、新鲜水果，在无医嘱的情况下，不要自行服用蜂胶、蜂王浆、花粉及一些含激素的口服液，特别是处于更年期的女性，更不要借助这些补品来改变雌激素水平下降的现状。下一页：自我按摩有效防治乳腺病下面介绍可以经常使用的四种自我按摩的方法推抚法：　　患者取坐位或侧卧位，充分暴露胸部。先在患侧乳房上撒些滑石粉或涂上少许石蜡油，然后双手全掌由乳房四周沿乳腺管轻轻向乳头方向推抚50-100次。揉压法：　　以手掌上的小鱼际或大鱼际着力于患部，在红肿胀痛处施以轻揉手法，有硬块的地方反复揉压数次，直至肿块柔软为止。揉、捏、拿法：　　以右手五指着力，抓起患侧乳房部，施以揉捏手法，一抓一松，反复施术10-15次。左手轻轻将乳头揪动数次，以扩张乳头部的输乳管。振荡法：　　以右手小鱼际部着力，从乳房肿结处，沿乳根向乳头方向作高速振荡推赶，反复3-5遍。局部出现有微热感时，效果更佳。小编推荐小常识：五个办法教您自查乳腺疾病&nbsp;1&nbsp;\n",
      "样本分词效果:很多/女性/乳腺/增生/特别/紧张/担心/这是/乳腺癌/前兆/其实/乳腺/增生/仅仅/女性/内分泌/失调/雌激素/增高/孕激素/降低/造成/乳腺/结构/紊乱/担心/一定/会/转变成/乳腺癌/乳腺/增生/容易/转癌/乳腺/增生症/很多/女性/乳腺/增生症/主要/表现/周期性/乳房/疼痛/乳腺/腺体/增厚/出现/团块/压痛/还会/情绪/改变/生气/紧张/发怒/焦虑/抑郁/工作/生活/规律/改变/劳累/天气/变化/会/疼痛/加重/妇女/平时/感到/乳房/疼痛/健康检查/时/医生/告诉/患有/乳腺/增生症/便/经常/感到/乳房/疼痛/患者/心情舒畅/时/乳房/疼痛/症状/会/减轻/乳腺/增生/会/容易/转成/乳腺癌/绝大多数/乳腺/增生症/患者/绝经/会/不治/愈/乳腺/增生/一定/会/转变成/乳腺癌/极少数/中度/重度/典型/乳腺/增生/可能/会/转变/乳腺癌/［/提示/］/乳房/上长/肿块/疼痛/仅仅/刺痛/钝/痛/非/哺乳期/妇女/忽然/出现/乳头/流水/考虑/可能/乳腺癌/应/提早去/医院/检查/精神/作用/非常/精神/过度/紧张/会/乳腺/增生症/加重/乳房/疼痛/更/明显/女性/总是/处于/怒/愁/忧/虑/不良情绪/状态/会/抑制/卵巢/排卵/功能/出现/孕酮/减少/雌激素/相对/增高/导致/乳腺/增生/一页/乳腺/增生/预防/关键/预防/乳腺/增生/保持/心情/舒畅/情绪/乐观/乳腺/增生/最好/防御/武器/年龄/16/50/岁/女性/应/定期/进行/乳腺/普查/月经/天为/最佳/检查/时机/自查/触诊/钼/钯/方式/检查/35/岁/女性/应该/年/做/一次/50/岁/女性/应/一年/一次/高危/人群/乳腺病/家族史/卵巢癌/腺体/癌/重度/增生/女性/应/半年/检查/一次/进行/动态/观察/20/35/岁/女性/应/年/进行/一次/红外线/乳腺/外科/检查/减少/人工流产/次数/减少/乳腺/增生/概率/生活/规律/适当/运动/平时/应/劳逸结合/睡眠/充足/少/熬夜/适当/进行/跑步/扩胸/增强/胸部/健美/运动/哺乳/时间/充分/女性/产后/哺乳/哺乳/不足/月/会/造成/乳汁/淤积/引发/乳腺/疾病/概率/升高/避免/激素/药物/美容/产品/使用/最好/不要/佩戴/紧/挤压/隆胸/效果/胸罩/影响/乳房/新陈代谢/淋巴/回流/导致/乳腺/增生/减少/高能量/补品/食品/饮食/清淡/为主/吃/绿叶/蔬菜/新鲜/水果/医嘱/情况/不要/自行/服用/蜂胶/蜂王浆/花粉/含/激素/口服液/特别/处于/更年期/女性/更/不要/借助/补品/改变/雌激素/水平/下降/现状/一页/自我/按摩/有效/防治/乳腺病/下面/介绍/经常/使用/四种/自我/按摩/方法/推抚法/　/　/患者/取/坐位/侧卧位/充分/暴露/胸部/先/患侧/乳房/上撒些/滑石粉/或涂/少许/石蜡油/双手/全掌/乳房/四周/乳腺/轻轻/乳头/方向/推抚/50/100/次/揉/压法/　/　/手掌/鱼际/大鱼际/着力/患部/红/肿胀/痛处/施以/轻揉/手法/硬块/地方/反复/揉/压/数次/直至/肿块/柔软/揉/捏/拿法/　/　/右手/五指/着力/抓起/患侧/乳房/部/施以/揉捏/手法/一抓/一松/反复/施术/10/15/次/左手/轻轻/乳头/揪动/数次/扩张/乳头/部/输乳管/振荡/法/　/　/右手/鱼际部/着力/乳房/肿结处/乳根/乳头/方向/作/高速/振荡/推赶/反复/遍/局部/出现/有微/热感/时/效果/更佳/小编/推荐/小常识/五个/办法/教/自查/乳腺/疾病\n",
      "topK10:[('乳腺', 24), ('增生', 13), ('女性', 11), ('乳房', 11), ('会', 10), ('\\u3000', 8), ('疼痛', 7), ('乳腺癌', 6), ('应', 6), ('增生症', 5)]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jieba 加载自己的词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "干饭人\n",
      "干饭人\n"
     ]
    }
   ],
   "source": [
    "text='干饭人'\n",
    "split_words=jieba.cut(text)\n",
    "print('/'.join(split_words))\n",
    "jieba.load_userdict('../../Data/learning-nlp-master/chapter-3/data/user_dict.utf8')\n",
    "split_words=jieba.cut(text)\n",
    "print('/'.join(split_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jieba分词进行词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as psg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Feng\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.015 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文/nz 分词/n 是/v 文本处理/n 不可或缺/l 的/uj 一步/m ！/x\n"
     ]
    }
   ],
   "source": [
    "sent='中文分词是文本处理不可或缺的一步！'\n",
    "seg_list=psg.cut(sent)\n",
    "print(' '.join('{0}/{1}'.format(w,t) for w,t in seg_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python36464bit9ffca756c41c4bc0870136837a4af8eb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
